# :pear: PEAR: Post-hoc Explainer Agreement Regularization

A repo for training neural networks for post hoc explainer agreement. More details about the results can be found at
<insert_link_here>


[//]: # (## Citing Our Work)
[//]: # ()
[//]: # (To cite our work, please reference the appropriate paper.)

## Getting Started

If you are intersted in using the :pear: PEAR package to train your own models, you can install the package through pip.

```$ pip install pear-xai```

You should then be able to run an example in a python interpreter:

```
$ python
>>> import pear
>>> pear.run_example()
```

If you are interested in cloning this repository and reproducing or building on our experiments, you can install the requirements manually as follows. (This code was developed and tested with Python 3.9.5)

After downloading the repository (or cloning it), install the requirements:

```$ pip install -r requirements.txt```

You can then open and run the Jupyter Notebook [tutorials](notebooks) on reproducing our results.
________________________________________________________________________________________________

## Contributing

We believe in open-source community driven software development. Please open issues and pull requests with any questions or improvements you have.